{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "def cargar_datos():\n",
    "    data_path = '../data'\n",
    "    files = os.listdir(data_path)\n",
    "    \n",
    "    df_list = []\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):  \n",
    "            file_path = os.path.join(data_path, file)\n",
    "\n",
    "            parts = file.split('_')\n",
    "\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            \n",
    "            year = parts[0]  \n",
    "            month_name = parts[2]  \n",
    "\n",
    "            if year not in ['2023', '2024']:\n",
    "                continue\n",
    "\n",
    "            # if month_name not in ['Gener', 'Febrer', 'Marc', 'Abril', 'Maig']:\n",
    "            if month_name not in ['Gener', 'Febrer', 'Marc', 'Abril', 'Maig']:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, low_memory=True, dtype=str, skiprows=lambda i: i % 1000 != 0)\n",
    "\n",
    "                df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
    "                df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
    "\n",
    "                # en base el last_reported creame la columna, year, month, day, hour, minute\n",
    "                df['year'] = df['last_reported'].dt.year\n",
    "                df['month'] = df['last_reported'].dt.month\n",
    "                df['day'] = df['last_reported'].dt.day\n",
    "                df['hour'] = df['last_reported'].dt.hour\n",
    "                df['minute'] = df['last_reported'].dt.minute\n",
    "\n",
    "                if 'traffic' in df.columns:\n",
    "                    df.drop(columns=['traffic'], inplace=True)\n",
    "                \n",
    "                if 'V1' in df.columns:\n",
    "                    df.drop(columns=['V1'], inplace=True)\n",
    "\n",
    "                # Parsear las columnas 'num_bikes_available','num_bikes_available_types.mechanical', 'num_bikes_available_types.ebike' a int\n",
    "                for col in ['num_bikes_available','num_docks_available','num_bikes_available_types.mechanical', 'num_bikes_available_types.ebike']:\n",
    "                    df[col] = df[col].astype('float64')\n",
    "\n",
    "                df_list.append(df)\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    merged_df = pd.concat(df_list, ignore_index=True) if df_list else None\n",
    "\n",
    "    if merged_df is not None:\n",
    "        df_2 = pd.read_csv('../data/Informacio_Estacions_Bicing_2025.csv', usecols=['station_id', 'lat', 'lon','capacity'], low_memory=False) #aqui faig el merge amb el segon dataset, només agafo les variables geoespacials\n",
    "        \n",
    "        merged_df['station_id'] = merged_df['station_id'].astype(str)\n",
    "        df_2['station_id'] = df_2['station_id'].astype(str)\n",
    "        \n",
    "        merged_df = merged_df.merge(df_2, on='station_id', how='left')\n",
    "\n",
    "    # Crea una columna que sea la suman 'num_bikes_available' + 'num_docks_available' que se llame sum_capacity\n",
    "    merged_df['sum_capacity'] = merged_df['num_bikes_available'] + merged_df['num_docks_available']\n",
    "\n",
    "    # Calcular la mediana de 'sum_capacity' para cada 'station_id'\n",
    "    median_capacity = merged_df.groupby('station_id')['sum_capacity'].median()\n",
    "\n",
    "    def impute_capacity(row):\n",
    "        if pd.isna(row['capacity']):\n",
    "            return median_capacity[row['station_id']]\n",
    "        else:\n",
    "            return row['capacity']\n",
    "\n",
    "    merged_df['capacity'] = merged_df.apply(impute_capacity, axis=1)\n",
    "    merged_df['diff_capacity_available'] = merged_df['capacity'] - (merged_df['num_bikes_available'] + merged_df['num_docks_available'])\n",
    "\n",
    "\n",
    "    # En las columnas que el diff_capacity_available sea > 0 sumamos este valor al num_docks_avaiable.\n",
    "    merged_df.loc[merged_df['diff_capacity_available'] > 0, 'num_docks_available'] += merged_df['diff_capacity_available']\n",
    "\n",
    "    # En las columnas que el diff_capacity_available sea < 0 restamos este valor al num_docks_available.\n",
    "    merged_df.loc[merged_df['diff_capacity_available'] < 0, 'num_docks_available'] += merged_df['diff_capacity_available']\n",
    "\n",
    "    # num_docks_available que nunca sea mas grande que capacity ni mas pequeño que 0\n",
    "    # Aseguramos que num_docks_available esté entre 0 y capacity, de forma row-wise.\n",
    "    merged_df['num_docks_available'] = merged_df.apply(\n",
    "        lambda row: min(max(row['num_docks_available'], 0), row['capacity']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Creamos la columna target que sera el % de bicis disponibles\n",
    "    merged_df['target'] = merged_df['num_docks_available'] / merged_df['capacity']\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CyclicalFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer para crear variables cíclicas (seno y coseno) a partir de columnas temporales.\n",
    "    Por defecto, transforma: month, day, hour y minute.\n",
    "    La columna 'year' se deja sin transformar.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        \"\"\"\n",
    "        columns: diccionario que define para cada columna el valor máximo (p.ej. {\"month\": 12, \"day\": 31, \"hour\": 24, \"minute\": 60})\n",
    "        Si se omite, se usan valores por defecto.\n",
    "        \"\"\"\n",
    "        if columns is None:\n",
    "            self.columns = {\"month\": 12, \"day\": 31, \"hour\": 24, \"minute\": 60}\n",
    "        else:\n",
    "            self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No es necesario aprender nada de X\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        for col, max_val in self.columns.items():\n",
    "            if col in X_.columns:\n",
    "                X_[f'{col}_sin'] = np.sin(2 * np.pi * X_[col].astype(float) / max_val)\n",
    "                X_[f'{col}_cos'] = np.cos(2 * np.pi * X_[col].astype(float) / max_val)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "status_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='NOT_IN_SERVICE')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore', categories=[['IN_SERVICE', 'MAINTENANCE', 'NOT_IN_SERVICE', 'PLANNED']])), # One-Hot Encoding\n",
    "])\n",
    "\n",
    "is_charging_station_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, drop='if_binary')),\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "cyclic_pipeline = Pipeline([\n",
    "    ('cyclic_transformer', CyclicalFeaturesTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('status', status_pipeline, ['status']),\n",
    "        ('is_charging_station', is_charging_station_pipeline, ['is_charging_station']),\n",
    "        ('ordinal', ordinal_pipeline, ['month','day','hour']),\n",
    "        ('cyclic', cyclic_pipeline, ['month','day','hour','minute']),\n",
    "        ('year', 'passthrough', ['year']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:40: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
      "/tmp/ipykernel_542754/1353534677.py:41: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['last_updated'] = pd.to_datetime(df['last_updated'], unit='s', errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "df_merge = cargar_datos()\n",
    "\n",
    "# transformed_data = preprocessor.fit_transform(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_542754/907563804.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_capacity['diff_bike_types'] = df_capacity['num_bikes_available_types.mechanical'] + df_capacity['num_bikes_available_types.ebike'] - df_capacity['num_bikes_available']\n",
      "/tmp/ipykernel_542754/907563804.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_capacity['diff_capacity_available'] = df_capacity['capacity'] - (df_capacity['num_bikes_available'] + df_capacity['num_docks_available'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capacity = df_merge[['capacity','num_bikes_available','num_bikes_available_types.mechanical', 'num_bikes_available_types.ebike', 'num_docks_available']]\n",
    "\n",
    "df_capacity['diff_bike_types'] = df_capacity['num_bikes_available_types.mechanical'] + df_capacity['num_bikes_available_types.ebike'] - df_capacity['num_bikes_available']\n",
    "df_capacity['diff_capacity_available'] = df_capacity['capacity'] - (df_capacity['num_bikes_available'] + df_capacity['num_docks_available'])\n",
    "\n",
    "# Dime el total de diff_capacity_available / entre los diff_capacity_available que no son iguales a 0\n",
    "df_capacity[df_capacity['diff_capacity_available'] == 0].shape[0] / df_capacity.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
