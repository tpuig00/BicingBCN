{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import dask.dataframe as dd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "def cargar_datos():\n",
    "    data_path = '../data'\n",
    "    files = os.listdir(data_path)\n",
    "    \n",
    "    df_list = []\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):  \n",
    "            file_path = os.path.join(data_path, file)\n",
    "\n",
    "            parts = file.split('_')\n",
    "\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            \n",
    "            year = parts[0]  \n",
    "            month_name = parts[2]  \n",
    "\n",
    "            if year not in ['2024']:\n",
    "            # if year not in ['2024']:\n",
    "\n",
    "                continue\n",
    "\n",
    "            #if month_name not in ['Gener', 'Febrer', 'Marc', 'Abril', 'Maig']:\n",
    "            if month_name not in ['Maig']:\n",
    "\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                #df = pd.read_csv(file_path, low_memory=True, dtype=str, skiprows=lambda i: i % 1000 != 0)\n",
    "                df = dd.read_csv(file_path, low_memory=True, dtype=str)\n",
    "\n",
    "\n",
    "                df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
    "\n",
    "                df['year'] = df['last_reported'].dt.year\n",
    "                df['month'] = df['last_reported'].dt.month\n",
    "                df['day'] = df['last_reported'].dt.day\n",
    "                df['hour'] = df['last_reported'].dt.hour\n",
    "\n",
    "                if 'traffic' in df.columns:\n",
    "                    df.drop(columns=['traffic'], inplace=True)\n",
    "                \n",
    "                if 'V1' in df.columns:\n",
    "                    df.drop(columns=['V1'], inplace=True)\n",
    "\n",
    "                # Convertir columnas a float\n",
    "                for col in ['num_bikes_available','num_docks_available','num_bikes_available_types.mechanical', 'num_bikes_available_types.ebike']:\n",
    "                    df[col] = df[col].astype('float64')\n",
    "\n",
    "                df_list.append(df)\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    merged_df = pd.concat(df_list, ignore_index=True) if df_list else None\n",
    "\n",
    "    if merged_df is not None:\n",
    "        df_2 = pd.read_csv('../Informacio_Estacions_Bicing_2025.csv', usecols=['station_id', 'lat', 'lon','capacity'], low_memory=False)\n",
    "\n",
    "        merged_df['station_id'] = merged_df['station_id'].astype('Int64')\n",
    "        df_2['station_id'] = df_2['station_id'].astype('Int64')\n",
    "        \n",
    "        merged_df = merged_df.merge(df_2, on='station_id', how='inner')\n",
    "\n",
    "    # Crear columna sum_capacity\n",
    "    merged_df['sum_capacity'] = merged_df['num_bikes_available'] + merged_df['num_docks_available']\n",
    "\n",
    "    # Calcular la mediana de sum_capacity por estación\n",
    "    median_capacity = merged_df.groupby('station_id')['sum_capacity'].median()\n",
    "\n",
    "    def impute_capacity(row):\n",
    "        return median_capacity[row['station_id']] if pd.isna(row['capacity']) else row['capacity']\n",
    "\n",
    "    merged_df['capacity'] = merged_df.apply(impute_capacity, axis=1)\n",
    "    # merged_df['diff_capacity_available'] = merged_df['capacity'] - (merged_df['num_bikes_available'] + merged_df['num_docks_available'])\n",
    "\n",
    "    # Asegurar límites de num_docks_available\n",
    "    merged_df['num_docks_available'] = merged_df.apply(\n",
    "        lambda row: min(max(row['num_docks_available'], 0), row['capacity']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Crear columna target (% de bicis disponibles)\n",
    "    merged_df['target'] = merged_df['num_docks_available'] / merged_df['capacity']\n",
    "\n",
    "    # **Agrupar a nivel de hora por estación**\n",
    "    aggregated_df = merged_df.groupby(['station_id', 'year', 'month', 'day', 'hour']).agg(\n",
    "        num_bikes_available=('num_bikes_available', 'mean'),\n",
    "        num_docks_available=('num_docks_available', 'mean'),\n",
    "        num_mechanical=('num_bikes_available_types.mechanical', 'median'),\n",
    "        num_ebike=('num_bikes_available_types.ebike', 'median'),\n",
    "        target=('target', 'mean'),\n",
    "        lat=('lat', 'first'),\n",
    "        lon=('lon', 'first'),\n",
    "        capacity=('capacity', 'first')\n",
    "    ).reset_index()\n",
    "\n",
    "    id = pd.read_csv('../data/metadata_sample_submission_2025.csv')\n",
    "\n",
    "    llista_stations = pd.unique(id['station_id'])\n",
    "\n",
    "    aggregated_df = aggregated_df[aggregated_df['station_id'].isin(llista_stations)]\n",
    "\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import dask.dataframe as dd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def cargar_datos():\n",
    "    data_path = '../data'\n",
    "    files = os.listdir(data_path)\n",
    "    \n",
    "    df_list = []\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):  \n",
    "            file_path = os.path.join(data_path, file)\n",
    "\n",
    "            parts = file.split('_')\n",
    "\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            \n",
    "            year = parts[0]  \n",
    "            month_name = parts[2]  \n",
    "\n",
    "            if year not in ['2024']:\n",
    "                continue\n",
    "\n",
    "            if month_name not in ['Gener']:\n",
    "                continue\n",
    "            \n",
    "\n",
    "            try:\n",
    "                df = dd.read_csv(file_path, low_memory=True, dtype=str)\n",
    "\n",
    "                df['last_reported'] = dd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
    "\n",
    "                df['year'] = df['last_reported'].dt.year\n",
    "                df['month'] = df['last_reported'].dt.month\n",
    "                df['day'] = df['last_reported'].dt.day\n",
    "                df['hour'] = df['last_reported'].dt.hour\n",
    "\n",
    "                if 'traffic' in df.columns:\n",
    "                    df = df.drop(columns=['traffic'])\n",
    "                \n",
    "                if 'V1' in df.columns:\n",
    "                    df = df.drop(columns=['V1'])\n",
    "\n",
    "                for col in ['num_bikes_available','num_docks_available','num_bikes_available_types.mechanical', 'num_bikes_available_types.ebike']:\n",
    "                    df[col] = df[col].astype('float64')\n",
    "\n",
    "                df_list.append(df)\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if df_list:\n",
    "        merged_df = dd.concat(df_list, axis=0, interleave_partitions=True)\n",
    "    else:\n",
    "        merged_df = None\n",
    "\n",
    "    if merged_df is not None:\n",
    "        df_2 = pd.read_csv('../Informacio_Estacions_Bicing_2025.csv', usecols=['station_id', 'lat', 'lon','capacity'], low_memory=False)\n",
    "\n",
    "        merged_df['station_id'] = merged_df['station_id'].astype('Int64')\n",
    "        df_2['station_id'] = df_2['station_id'].astype('Int64')\n",
    "        \n",
    "        merged_df = merged_df.merge(df_2, on='station_id', how='inner')\n",
    "\n",
    "        merged_df['sum_capacity'] = merged_df['num_bikes_available'] + merged_df['num_docks_available']\n",
    "\n",
    "        median_capacity = merged_df.groupby('station_id')['sum_capacity'].median().compute()\n",
    "\n",
    "        def impute_capacity(row):\n",
    "            return median_capacity[row['station_id']] if pd.isna(row['capacity']) else row['capacity']\n",
    "\n",
    "        merged_df['capacity'] = merged_df.apply(impute_capacity, axis=1, meta=('capacity', 'float64'))\n",
    "\n",
    "        merged_df['num_docks_available'] = merged_df.apply(\n",
    "            lambda row: min(max(row['num_docks_available'], 0), row['capacity']),\n",
    "            axis=1, meta=('num_docks_available', 'float64')\n",
    "        )\n",
    "\n",
    "        merged_df['target'] = merged_df['num_docks_available'] / merged_df['capacity']\n",
    "\n",
    "        aggregated_df = merged_df.groupby(['station_id', 'year', 'month', 'day', 'hour']).agg(\n",
    "            num_bikes_available=('num_bikes_available', 'mean'),\n",
    "            num_docks_available=('num_docks_available', 'mean'),\n",
    "            num_mechanical=('num_bikes_available_types.mechanical', 'median'),\n",
    "            num_ebike=('num_bikes_available_types.ebike', 'median'),\n",
    "            target=('target', 'mean'),\n",
    "            lat=('lat', 'first'),\n",
    "            lon=('lon', 'first'),\n",
    "            capacity=('capacity', 'first')\n",
    "        ).reset_index().compute()\n",
    "\n",
    "        id = pd.read_csv('../data/metadata_sample_submission_2025.csv')\n",
    "\n",
    "        llista_stations = pd.unique(id['station_id'])\n",
    "\n",
    "        aggregated_df = aggregated_df[aggregated_df['station_id'].isin(llista_stations)]\n",
    "\n",
    "        return aggregated_df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CyclicalFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer para crear variables cíclicas (seno y coseno) a partir de columnas temporales.\n",
    "    Por defecto, transforma: month, day, hour y minute.\n",
    "    La columna 'year' se deja sin transformar.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        \"\"\"\n",
    "        columns: diccionario que define para cada columna el valor máximo (p.ej. {\"month\": 12, \"day\": 31, \"hour\": 24, \"minute\": 60})\n",
    "        Si se omite, se usan valores por defecto.\n",
    "        \"\"\"\n",
    "        if columns is None:\n",
    "            self.columns = {\"month\": 12, \"day\": 31, \"hour\": 24, \"minute\": 60}\n",
    "        else:\n",
    "            self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No es necesario aprender nada de X\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        for col, max_val in self.columns.items():\n",
    "            if col in X_.columns:\n",
    "                X_[f'{col}_sin'] = np.sin(2 * np.pi * X_[col].astype(float) / max_val)\n",
    "                X_[f'{col}_cos'] = np.cos(2 * np.pi * X_[col].astype(float) / max_val)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "status_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='NOT_IN_SERVICE')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore', categories=[['IN_SERVICE', 'MAINTENANCE', 'NOT_IN_SERVICE', 'PLANNED']])), # One-Hot Encoding\n",
    "])\n",
    "\n",
    "is_charging_station_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, drop='if_binary')),\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "cyclic_pipeline = Pipeline([\n",
    "    ('cyclic_transformer', CyclicalFeaturesTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('status', status_pipeline, ['status']),\n",
    "        ('is_charging_station', is_charging_station_pipeline, ['is_charging_station']),\n",
    "        ('ordinal', ordinal_pipeline, ['month','day','hour']),\n",
    "        ('cyclic', cyclic_pipeline, ['month','day','hour','minute']),\n",
    "        ('year', 'passthrough', ['year']),\n",
    "        # CREAR COLUMNA FESTIVO (0/1) A PARTIR DE 'day' y 'month'\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n",
      "/home/tplan/anaconda3/lib/python3.12/site-packages/dask_expr/_expr.py:1466: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  return get_meta_library(args[0]).to_datetime(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_merge = cargar_datos()\n",
    "\n",
    "# transformed_data = preprocessor.fit_transform(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27085833976558277"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capacity = df_merge[['capacity', 'num_bikes_available', 'num_mechanical', 'num_ebike', 'num_docks_available']].copy()\n",
    "\n",
    "df_capacity['diff_bike_types'] = df_capacity['num_mechanical'] + df_capacity['num_ebike'] - df_capacity['num_bikes_available']\n",
    "df_capacity['diff_capacity_available'] = df_capacity['capacity'] - (df_capacity['num_bikes_available'] + df_capacity['num_docks_available'])\n",
    "\n",
    "# Dime el total de diff_capacity_available / entre los diff_capacity_available que no son iguales a 0\n",
    "df_capacity[df_capacity['diff_capacity_available'] == 0].shape[0] / df_capacity.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_bikes_available",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_docks_available",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_mechanical",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_ebike",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "capacity",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "69d95829-507c-4054-8ab4-32e0b8b9d224",
       "rows": [
        [
         "0",
         "1",
         "2024.0",
         "4.0",
         "30.0",
         "21.0",
         "20.0",
         "25.0",
         "19.0",
         "1.0",
         "0.5434782608695652",
         "41.3979779",
         "2.1801069",
         "46"
        ],
        [
         "1",
         "1",
         "2024.0",
         "4.0",
         "30.0",
         "22.0",
         "25.25",
         "19.75",
         "20.0",
         "6.0",
         "0.42934782608695654",
         "41.3979779",
         "2.1801069",
         "46"
        ],
        [
         "2",
         "1",
         "2024.0",
         "4.0",
         "30.0",
         "23.0",
         "32.333333333333336",
         "12.666666666666666",
         "24.5",
         "9.0",
         "0.2753623188405797",
         "41.3979779",
         "2.1801069",
         "46"
        ],
        [
         "3",
         "1",
         "2024.0",
         "5.0",
         "1.0",
         "0.0",
         "25.916666666666668",
         "19.083333333333332",
         "16.5",
         "6.5",
         "0.4148550724637681",
         "41.3979779",
         "2.1801069",
         "46"
        ],
        [
         "4",
         "1",
         "2024.0",
         "5.0",
         "1.0",
         "1.0",
         "18.416666666666668",
         "26.583333333333332",
         "15.0",
         "4.0",
         "0.5778985507246377",
         "41.3979779",
         "2.1801069",
         "46"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>num_bikes_available</th>\n",
       "      <th>num_docks_available</th>\n",
       "      <th>num_mechanical</th>\n",
       "      <th>num_ebike</th>\n",
       "      <th>target</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.429348</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>24.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.916667</td>\n",
       "      <td>19.083333</td>\n",
       "      <td>16.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.414855</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.416667</td>\n",
       "      <td>26.583333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.577899</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id    year  month   day  hour  num_bikes_available  \\\n",
       "0           1  2024.0    4.0  30.0  21.0            20.000000   \n",
       "1           1  2024.0    4.0  30.0  22.0            25.250000   \n",
       "2           1  2024.0    4.0  30.0  23.0            32.333333   \n",
       "3           1  2024.0    5.0   1.0   0.0            25.916667   \n",
       "4           1  2024.0    5.0   1.0   1.0            18.416667   \n",
       "\n",
       "   num_docks_available  num_mechanical  num_ebike    target        lat  \\\n",
       "0            25.000000            19.0        1.0  0.543478  41.397978   \n",
       "1            19.750000            20.0        6.0  0.429348  41.397978   \n",
       "2            12.666667            24.5        9.0  0.275362  41.397978   \n",
       "3            19.083333            16.5        6.5  0.414855  41.397978   \n",
       "4            26.583333            15.0        4.0  0.577899  41.397978   \n",
       "\n",
       "        lon  capacity  \n",
       "0  2.180107        46  \n",
       "1  2.180107        46  \n",
       "2  2.180107        46  \n",
       "3  2.180107        46  \n",
       "4  2.180107        46  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.sort_values(by=['station_id','year', 'month', 'day', 'hour'], ascending=True, inplace=True)\n",
    "df_merge.head()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_id",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_bikes_available",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_docks_available",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_mechanical",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_ebike",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "capacity",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1e56a221-76d6-4e7c-82e8-ec6cb35bb703",
       "rows": [
        [
         "4",
         "1",
         "2024.0",
         "5.0",
         "1.0",
         "1.0",
         "18.416666666666668",
         "26.583333333333332",
         "15.0",
         "4.0",
         "0.5778985507246377",
         "41.3979779",
         "2.1801069",
         "46"
        ],
        [
         "5",
         "1",
         "2024.0",
         "5.0",
         "1.0",
         "2.0",
         "16.75",
         "28.25",
         "14.0",
         "2.0",
         "0.6141304347826088",
         "41.3979779",
         "2.1801069",
         "46"
        ],
        [
         "6",
         "1",
         "2024.0",
         "5.0",
         "1.0",
         "3.0",
         "17.0",
         "28.0",
         "16.0",
         "1.0",
         "0.6086956521739131",
         "41.3979779",
         "2.1801069",
         "46"
        ],
        [
         "7",
         "1",
         "2024.0",
         "5.0",
         "1.0",
         "4.0",
         "17.166666666666668",
         "27.833333333333332",
         "17.0",
         "0.0",
         "0.605072463768116",
         "41.3979779",
         "2.1801069",
         "46"
        ],
        [
         "8",
         "1",
         "2024.0",
         "5.0",
         "1.0",
         "5.0",
         "18.666666666666668",
         "26.333333333333332",
         "19.0",
         "0.0",
         "0.572463768115942",
         "41.3979779",
         "2.1801069",
         "46"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>num_bikes_available</th>\n",
       "      <th>num_docks_available</th>\n",
       "      <th>num_mechanical</th>\n",
       "      <th>num_ebike</th>\n",
       "      <th>target</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.416667</td>\n",
       "      <td>26.583333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.577899</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>27.833333</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605072</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572464</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id    year  month  day  hour  num_bikes_available  \\\n",
       "4           1  2024.0    5.0  1.0   1.0            18.416667   \n",
       "5           1  2024.0    5.0  1.0   2.0            16.750000   \n",
       "6           1  2024.0    5.0  1.0   3.0            17.000000   \n",
       "7           1  2024.0    5.0  1.0   4.0            17.166667   \n",
       "8           1  2024.0    5.0  1.0   5.0            18.666667   \n",
       "\n",
       "   num_docks_available  num_mechanical  num_ebike    target        lat  \\\n",
       "4            26.583333            15.0        4.0  0.577899  41.397978   \n",
       "5            28.250000            14.0        2.0  0.614130  41.397978   \n",
       "6            28.000000            16.0        1.0  0.608696  41.397978   \n",
       "7            27.833333            17.0        0.0  0.605072  41.397978   \n",
       "8            26.333333            19.0        0.0  0.572464  41.397978   \n",
       "\n",
       "        lon  capacity  \n",
       "4  2.180107        46  \n",
       "5  2.180107        46  \n",
       "6  2.180107        46  \n",
       "7  2.180107        46  \n",
       "8  2.180107        46  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    station_id    year  month  day  hour  num_bikes_available  \\\n",
      "4          1.0  2024.0    1.0  1.0   2.0            14.500000   \n",
      "9          1.0  2024.0    1.0  1.0   7.0            13.000000   \n",
      "14         1.0  2024.0    1.0  1.0  12.0             4.666667   \n",
      "19         1.0  2024.0    1.0  1.0  17.0             5.666667   \n",
      "24         1.0  2024.0    1.0  1.0  22.0            10.000000   \n",
      "\n",
      "    num_docks_available  num_mechanical  num_ebike    target        lat  \\\n",
      "4             30.500000             5.5        9.5  0.663043  41.397978   \n",
      "9             32.000000             9.0        4.0  0.695652  41.397978   \n",
      "14            40.333333             1.0        4.0  0.876812  41.397978   \n",
      "19            39.333333             2.0        4.0  0.855072  41.397978   \n",
      "24            35.000000             4.0        6.0  0.760870  41.397978   \n",
      "\n",
      "         lon  capacity  4h_before  3h_before  2h_before  1h_before  \n",
      "4   2.180107      46.0   0.717391   0.768116   0.748188   0.764493  \n",
      "9   2.180107      46.0   0.681159   0.733696   0.740803   0.721344  \n",
      "14  2.180107      46.0   0.695652   0.715719   0.807971   0.809783  \n",
      "19  2.180107      46.0   0.882246   0.864130   0.838768   0.807971  \n",
      "24  2.180107      46.0   0.907609   0.898551   0.815217   0.697464  \n"
     ]
    }
   ],
   "source": [
    "#suposant que comencem per l'inici dun dia(elimino les 4 hores del dia anterior del mes anterior, ja que per defecte surten)\n",
    "df_merge = df_merge.iloc[4:]\n",
    "df_merge.head()  \n",
    "\n",
    "#funcio per afegir les 4h anteriors\n",
    "def crear_campos_lags(df):\n",
    "    resultados = []\n",
    "    # Agrupamos por station_id\n",
    "    for station, grupo in df.groupby('station_id'):\n",
    "        # Aseguramos el orden cronológico\n",
    "        grupo = grupo.sort_values(by=['year', 'month', 'day', 'hour']).reset_index(drop=True)\n",
    "        n = len(grupo)\n",
    "        # Iteramos empezando en el índice 4 y avanzamos de 5 en 5\n",
    "        for i in range(4, n, 5):\n",
    "            if i - 4 >= 0:\n",
    "                fila = grupo.loc[i].copy()\n",
    "                # Agregamos los valores de 'target' de las 4 horas previas\n",
    "                fila['ctx-4'] = grupo.loc[i - 4, 'target']\n",
    "                fila['ctx-3'] = grupo.loc[i - 3, 'target']\n",
    "                fila['ctx-2'] = grupo.loc[i - 2, 'target']\n",
    "                fila['ctx-1'] = grupo.loc[i - 1, 'target']\n",
    "                \n",
    "                resultados.append(fila)\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "# Aplicamos la función al DataFrame df_merge\n",
    "df_merge_final = crear_campos_lags(df_merge)\n",
    "\n",
    "print(df_merge_final.head())  # Ver las primeras filas del nuevo DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merge_final[['station_id','month', 'day', 'hour', '1h_before', '2h_before', '3h_before', '4h_before']]\n",
    "y = df_merge_final['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Random forest\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, random_state=42)\n",
    "\n",
    "# Apply preprocessing pipeline\n",
    "X_train_transformed = X_train\n",
    "X_test_transformed = X_test\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_rf = rf_model.predict(X_train_transformed)\n",
    "y_test_pred_rf = rf_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate Model\n",
    "train_mse_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "test_mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "\n",
    "print(f'Train MSE: {train_mse_rf}')\n",
    "print(f'Test MSE: {test_mse_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def linear_regression(X,y, size):\n",
    "#Separamos train y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X ,y , test_size= size, random_state=42)\n",
    "\n",
    "    lm = LinearRegression()\n",
    "#Entrenamiento modelo\n",
    "    lm.fit(X_train, y_train)\n",
    "#Predict\n",
    "    y_pred = lm.predict(X_test)\n",
    "#Metricas\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return  r2, mse, mae\n",
    "\n",
    "\n",
    "#RandomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def RandomForest(X,y, size):\n",
    "#Separamos train y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X ,y , test_size= size, random_state=42)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators = 100, random_state= 42)\n",
    "#Entrenamiento modelo\n",
    "    rf.fit(X_train, y_train)\n",
    "#Predict\n",
    "    y_pred = rf.predict(X_test)\n",
    "#Metricas\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "#Factoring Importance\n",
    "    feature_importance = rf.feature_importances_\n",
    "    feature_names = X_test.columns\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return  r2, mse, mae, importance_df, rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Métrica  Regresión Lineal  Random Forest\n",
      "0      R²          0.803255       0.803612\n",
      "1     MSE          0.011856       0.011834\n",
      "2     MAE          0.073037       0.073680\n",
      "Importancia de las características:\n",
      "      Feature  Importance\n",
      "4   1h_before    0.827825\n",
      "5   2h_before    0.045118\n",
      "6   3h_before    0.029135\n",
      "0  station_id    0.028805\n",
      "7   4h_before    0.028627\n",
      "3        hour    0.021051\n",
      "2         day    0.019440\n",
      "1       month    0.000000\n"
     ]
    }
   ],
   "source": [
    "r2_linear, mse_linear, mae_linear = linear_regression(X,y, 0.3)\n",
    "r2_rf, mse_rf, mae_rf, importance_df,rf = RandomForest(X, y, 0.3)\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Métrica': ['R²', 'MSE', 'MAE'],\n",
    "    'Regresión Lineal': [r2_linear, mse_linear, mae_linear],\n",
    "    'Random Forest': [r2_rf, mse_rf, mae_rf]\n",
    "})\n",
    "print(metrics_df)\n",
    "print(\"Importancia de las características:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones añadidas y guardadas en 'metadata_sample_submission_with_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('../metadata_sample_submission_2025.csv')\n",
    "\n",
    "# Seleccionar las características para predecir\n",
    "X_predict = df[['station_id', 'month', 'day', 'hour', '1h_before', '2h_before', '3h_before', '4h_before']]\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = rf.predict(X_predict)\n",
    "\n",
    "# Añadir las predicciones como una nueva columna en el DataFrame\n",
    "df['predictions'] = predictions\n",
    "\n",
    "# Guardar el DataFrame con las predicciones en un nuevo archivo CSV\n",
    "df.to_csv('metadata_sample_submission_with_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predicciones añadidas y guardadas en 'metadata_sample_submission_with_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[['index','predictions']]\n",
    "df_final.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
