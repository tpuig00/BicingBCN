{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "def cargar_datos():\n",
    "    data_path = '../data'\n",
    "    files = os.listdir(data_path)\n",
    "    \n",
    "    df_list = []\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):  \n",
    "            file_path = os.path.join(data_path, file)\n",
    "\n",
    "            parts = file.split('_')\n",
    "\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            \n",
    "            year = parts[0]  \n",
    "            month_name = parts[2]  \n",
    "\n",
    "            #if year not in ['2023', '2024']:\n",
    "            if year not in ['2024']:\n",
    "\n",
    "                continue\n",
    "\n",
    "            #if month_name not in ['Gener', 'Febrer', 'Marc', 'Abril', 'Maig']:\n",
    "            if month_name not in ['Maig']:\n",
    "\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                #df = pd.read_csv(file_path, low_memory=True, dtype=str, skiprows=lambda i: i % 1000 != 0)\n",
    "                df = pd.read_csv(file_path, low_memory=True, dtype=str)\n",
    "\n",
    "\n",
    "                df['last_reported'] = pd.to_datetime(df['last_reported'], unit='s', errors='coerce')\n",
    "\n",
    "                df['year'] = df['last_reported'].dt.year\n",
    "                df['month'] = df['last_reported'].dt.month\n",
    "                df['day'] = df['last_reported'].dt.day\n",
    "                df['hour'] = df['last_reported'].dt.hour\n",
    "\n",
    "                if 'traffic' in df.columns:\n",
    "                    df.drop(columns=['traffic'], inplace=True)\n",
    "                \n",
    "                if 'V1' in df.columns:\n",
    "                    df.drop(columns=['V1'], inplace=True)\n",
    "\n",
    "                # Convertir columnas a float\n",
    "                for col in ['num_bikes_available','num_docks_available','num_bikes_available_types.mechanical', 'num_bikes_available_types.ebike']:\n",
    "                    df[col] = df[col].astype('float64')\n",
    "\n",
    "                df_list.append(df)\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    merged_df = pd.concat(df_list, ignore_index=True) if df_list else None\n",
    "\n",
    "    if merged_df is not None:\n",
    "        df_2 = pd.read_csv('../Informacio_Estacions_Bicing_2025.csv', usecols=['station_id', 'lat', 'lon','capacity'], low_memory=False)\n",
    "\n",
    "        #merged_df['station_id'] = merged_df['station_id'].astype(int) MIRAR SI FUNCIONA \n",
    "        #df_2['station_id'] = df_2['station_id'].astype(int) MIRAR SI FUNCIONA\n",
    "        merged_df['station_id'] = merged_df['station_id'].astype('Int64')\n",
    "        df_2['station_id'] = df_2['station_id'].astype('Int64')\n",
    "        \n",
    "        merged_df = merged_df.merge(df_2, on='station_id', how='inner')\n",
    "\n",
    "    # Crear columna sum_capacity\n",
    "    merged_df['sum_capacity'] = merged_df['num_bikes_available'] + merged_df['num_docks_available']\n",
    "\n",
    "    # Calcular la mediana de sum_capacity por estación\n",
    "    median_capacity = merged_df.groupby('station_id')['sum_capacity'].median()\n",
    "\n",
    "    def impute_capacity(row):\n",
    "        return median_capacity[row['station_id']] if pd.isna(row['capacity']) else row['capacity']\n",
    "\n",
    "    merged_df['capacity'] = merged_df.apply(impute_capacity, axis=1)\n",
    "    # merged_df['diff_capacity_available'] = merged_df['capacity'] - (merged_df['num_bikes_available'] + merged_df['num_docks_available'])\n",
    "\n",
    "    # Asegurar límites de num_docks_available\n",
    "    merged_df['num_docks_available'] = merged_df.apply(\n",
    "        lambda row: min(max(row['num_docks_available'], 0), row['capacity']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Crear columna target (% de bicis disponibles)\n",
    "    merged_df['target'] = merged_df['num_docks_available'] / merged_df['capacity']\n",
    "\n",
    "    # **Agrupar a nivel de hora por estación**\n",
    "    aggregated_df = merged_df.groupby(['station_id', 'year', 'month', 'day', 'hour']).agg(\n",
    "        num_bikes_available=('num_bikes_available', 'mean'),\n",
    "        num_docks_available=('num_docks_available', 'mean'),\n",
    "        num_mechanical=('num_bikes_available_types.mechanical', 'median'),\n",
    "        num_ebike=('num_bikes_available_types.ebike', 'median'),\n",
    "        target=('target', 'mean'),\n",
    "        lat=('lat', 'first'),\n",
    "        lon=('lon', 'first'),\n",
    "        capacity=('capacity', 'first')\n",
    "    ).reset_index()\n",
    "\n",
    "    id = pd.read_csv('../data/metadata_sample_submission_2025.csv')\n",
    "\n",
    "    llista_stations = pd.unique(id['station_id'])\n",
    "\n",
    "    aggregated_df = aggregated_df[aggregated_df['station_id'].isin(llista_stations)]\n",
    "\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CyclicalFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer para crear variables cíclicas (seno y coseno) a partir de columnas temporales.\n",
    "    Por defecto, transforma: month, day, hour y minute.\n",
    "    La columna 'year' se deja sin transformar.\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        \"\"\"\n",
    "        columns: diccionario que define para cada columna el valor máximo (p.ej. {\"month\": 12, \"day\": 31, \"hour\": 24, \"minute\": 60})\n",
    "        Si se omite, se usan valores por defecto.\n",
    "        \"\"\"\n",
    "        if columns is None:\n",
    "            self.columns = {\"month\": 12, \"day\": 31, \"hour\": 24, \"minute\": 60}\n",
    "        else:\n",
    "            self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # No es necesario aprender nada de X\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        for col, max_val in self.columns.items():\n",
    "            if col in X_.columns:\n",
    "                X_[f'{col}_sin'] = np.sin(2 * np.pi * X_[col].astype(float) / max_val)\n",
    "                X_[f'{col}_cos'] = np.cos(2 * np.pi * X_[col].astype(float) / max_val)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "status_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='NOT_IN_SERVICE')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore', categories=[['IN_SERVICE', 'MAINTENANCE', 'NOT_IN_SERVICE', 'PLANNED']])), # One-Hot Encoding\n",
    "])\n",
    "\n",
    "is_charging_station_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, drop='if_binary')),\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "cyclic_pipeline = Pipeline([\n",
    "    ('cyclic_transformer', CyclicalFeaturesTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('status', status_pipeline, ['status']),\n",
    "        ('is_charging_station', is_charging_station_pipeline, ['is_charging_station']),\n",
    "        ('ordinal', ordinal_pipeline, ['month','day','hour']),\n",
    "        ('cyclic', cyclic_pipeline, ['month','day','hour','minute']),\n",
    "        ('year', 'passthrough', ['year']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_merge \u001b[38;5;241m=\u001b[39m \u001b[43mcargar_datos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# transformed_data = preprocessor.fit_transform(df_merge)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 42\u001b[0m, in \u001b[0;36mcargar_datos\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m#df = pd.read_csv(file_path, low_memory=True, dtype=str, skiprows=lambda i: i % 1000 != 0)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_reported\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_reported\u001b[39m\u001b[38;5;124m'\u001b[39m], unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_reported\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/c_parser_wrapper.py:236\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/c_parser_wrapper.py:369\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    367\u001b[0m arrs \u001b[38;5;241m=\u001b[39m [chunk\u001b[38;5;241m.\u001b[39mpop(name) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# Check each arr for consistent types.\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m dtypes \u001b[38;5;241m=\u001b[39m {a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrs}\n\u001b[1;32m    370\u001b[0m non_cat_dtypes \u001b[38;5;241m=\u001b[39m {x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dtypes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, CategoricalDtype)}\n\u001b[1;32m    372\u001b[0m dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_merge = cargar_datos()\n",
    "# transformed_data = preprocessor.fit_transform(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45218403479752495"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capacity = df_merge[['capacity', 'num_bikes_available', 'num_mechanical', 'num_ebike', 'num_docks_available']].copy()\n",
    "\n",
    "df_capacity['diff_bike_types'] = df_capacity['num_mechanical'] + df_capacity['num_ebike'] - df_capacity['num_bikes_available']\n",
    "df_capacity['diff_capacity_available'] = df_capacity['capacity'] - (df_capacity['num_bikes_available'] + df_capacity['num_docks_available'])\n",
    "\n",
    "# Dime el total de diff_capacity_available / entre los diff_capacity_available que no son iguales a 0\n",
    "df_capacity[df_capacity['diff_capacity_available'] == 0].shape[0] / df_capacity.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "hour",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "num_bikes_available",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_docks_available",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_mechanical",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_ebike",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "capacity",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "492d4d21-c781-4330-9754-01c4611627c0",
       "rows": [
        [
         "0",
         "1",
         "2023",
         "1",
         "4",
         "0",
         "11.0",
         "34.0",
         "10.0",
         "1.0",
         "0.7391304347826086",
         "41.3979779",
         "2.1801069",
         "46.0"
        ],
        [
         "1",
         "1",
         "2023",
         "1",
         "7",
         "5",
         "13.0",
         "32.0",
         "13.0",
         "0.0",
         "0.6956521739130435",
         "41.3979779",
         "2.1801069",
         "46.0"
        ],
        [
         "2",
         "1",
         "2023",
         "1",
         "8",
         "23",
         "13.0",
         "32.0",
         "10.0",
         "3.0",
         "0.6956521739130435",
         "41.3979779",
         "2.1801069",
         "46.0"
        ],
        [
         "3",
         "1",
         "2023",
         "1",
         "14",
         "21",
         "5.0",
         "40.0",
         "4.0",
         "1.0",
         "0.8695652173913043",
         "41.3979779",
         "2.1801069",
         "46.0"
        ],
        [
         "4",
         "1",
         "2023",
         "1",
         "15",
         "10",
         "10.0",
         "35.0",
         "9.0",
         "1.0",
         "0.7608695652173914",
         "41.3979779",
         "2.1801069",
         "46.0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>num_bikes_available</th>\n",
       "      <th>num_docks_available</th>\n",
       "      <th>num_mechanical</th>\n",
       "      <th>num_ebike</th>\n",
       "      <th>target</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id  year  month  day  hour  num_bikes_available  \\\n",
       "0           1  2023      1    4     0                 11.0   \n",
       "1           1  2023      1    7     5                 13.0   \n",
       "2           1  2023      1    8    23                 13.0   \n",
       "3           1  2023      1   14    21                  5.0   \n",
       "4           1  2023      1   15    10                 10.0   \n",
       "\n",
       "   num_docks_available  num_mechanical  num_ebike    target        lat  \\\n",
       "0                 34.0            10.0        1.0  0.739130  41.397978   \n",
       "1                 32.0            13.0        0.0  0.695652  41.397978   \n",
       "2                 32.0            10.0        3.0  0.695652  41.397978   \n",
       "3                 40.0             4.0        1.0  0.869565  41.397978   \n",
       "4                 35.0             9.0        1.0  0.760870  41.397978   \n",
       "\n",
       "        lon  capacity  \n",
       "0  2.180107      46.0  \n",
       "1  2.180107      46.0  \n",
       "2  2.180107      46.0  \n",
       "3  2.180107      46.0  \n",
       "4  2.180107      46.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.sort_values(by=['station_id','year', 'month', 'day', 'hour'], ascending=True, inplace=True)\n",
    "df_merge.head()  # Ahora sí mostrará las primeras filas ordenadas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
